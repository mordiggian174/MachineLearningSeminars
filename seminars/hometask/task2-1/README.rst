####################
Домашнее задание 2-1
####################

Описание
========

В рамках данного задания требуется выполнить 5 задач. Каждая задача должна быть оформлена в виде отдельного task{1,2,3,4,5}.ipynb файла и tensorboard{1,2,3,4,5}.zip файла.
В каждом файле *.ipynb должно быть:

- построение архитектуры;
- выполнен процесс обучения;
- показан пример работы модели до обучения и после;

Файл .zip должен содержать результаты эксперимента в формате tensorboard для каждой из задач:

- для каждого набора параметров свой график зависимости качества от обучения (если требуется в задаче);
- примеры работы модели в процессе обучения модели.

Для каждой задачи должны быть представлены выводы:

- какой результат ожидали;
- какой не ожидали;
- что было не ясно.

Код и эксперимент должен быть понятным внешнему читателю:

- В коде должны быть коментарии;
- Названия переменных должно быть интерпретируемые.

P.S. Рекомендуется все вычисления проводить на google colab в режиме cuda.

P.S.S. Рекомендуется использовать backup моделей при обучении на google drive.

Задачи
======

Задача 1. Анализ модели CNN
---------------------------
Провести анализ качества аппроксимации выборки EMNIST-letters моделью сверточной нейронной сети в зависимости от:

- размера ядра (можно ввести ограничение, что на каждом слое размер ядра одинаковый);
- числа слоев;
- от пулинга;
- добавления BatchNorm;
- параметра dropout.

Все выводы должны быть представленны в формате tensorboard (каждый набор параметров, свой график, пример `16-й семинар <https://github.com/andriygav/MachineLearningSeminars/blob/master/sem16/main.ipynb>`_).

P.S. Выборку можно взять из `torchvision <https://pytorch.org/vision/0.8/datasets.html#emnist>`_.

P.S.S Если не работает скачиваение EMNIST использовать `FahionMnist <https://pytorch.org/vision/0.8/datasets.html#fashion-mnist>`_.

Пояснение: В данном задании важно продемонстрировать умение строить различные структуры модели CNN. Не обязательно выполнять перебор всех вариантов нейросети (проходить по сетке гиперпараметров), но описание экспериментов должны присутвовать.

Задача 2. Анализ модели LSTM
----------------------------
Провести анализ качества аппроксимации выборки NERUS (POS tag) моделью LSTM в зависимости от:

- размера слоя;
- числа слоев;
- параметра dropout;
- добавления BatchNorm;
- размера словаря;
- *токенизатора* - дополнительное задание (со звездочкой).

Все выводы должны быть представленны в формате tensorboard (каждый набор параметров, свой график, пример --- второй семинар).

P.S. Выборку можно взять из `github <https://github.com/natasha/nerus>`_.

P.S.S. Предлагается использовать разные варианты токенизатора:

- взять все слова из обучающего датасета;
- использовать предобученые BPE токены из LaBSE модели (пока не сильно важно что это, об этом 4й семинар):

.. code-block:: python

    from transformers import AutoTokenizer, AutoModel

    tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/LaBSE")
    
    model = YourLSTMmodel()
    tokens = tokenizer(['Hello Mr. Bernz.', 'I am Homer Simpsone'], padding=True,
                       truncation=True, 
                       max_length=510, 
                       return_tensors='pt')['tokens_ids']
    answer = model(tokens)
    
P.S.S.S. Сначала выборку нужно привести формат согласно Вашему токенизатору, то есть выполнить отображение исходной выборки с токенами в исходном формате в выборку с токенами, которые согласованы с Вашим токенизатором.

Пояснение: В данном задании важно продемонстрировать умение работать с моделью LSTM, а также умение преобразовать данные под разные модели и данные. В качестве базового решения продемостировать аппроксимации "чистой" выборки NERUS без преобразования данных (взять исходные токены из выборки). Более сложным является задание, когда Вам дают другой токенизатор предложения и доступные данные нужно переформатировать в нужный Вам формат данных.

Задача 3. Модель автокодировщика
--------------------------------
Провести анализ модели автокодировщика (не вариационного) для выборки Twitter (эмбединги предложений). Требуется сравнить качество востановления предложения в зависимости от:

- размера слоя;
- числа слоев;
- параметра dropout;
- добавления BatchNorm;
- размера словаря;
- *токенизатора* - дополнительное задание (со звездочкой.

Все выводы должны быть представленны в формате tensorboard (каждый набор параметров, свой график, пример --- второй семинар).

P.S. Выборку можно взять из `семинара 17 <https://github.com/andriygav/MachineLearningSeminars/blob/master/sem17/data/dataset.csv.dvc>`_. Пример как использовать DVC для выгрузки данных представлен в `ноутбуке <https://github.com/andriygav/MachineLearningSeminars/blob/master/sem17/main.ipynb>`_.

P.S.S. Рекомендуется использовать предобученый BPE токенизатор для снижения размерности словаря (см. задачу 2).

Задача 4. Вариационный автокодировщик
-------------------------------------
Провести синтетический эксперимент с моделью вариационного автокодировщика в случае, если данные не из бернуливского распределения, а из нормального. В качестве данных использовать синтетическую выборку, которая состоит из нескольких кластеров в виде гаусиан (каждый кластер является множеством векторов из нормального распределения с парметрами mu, Sigma). В рамках эксперимента требуется исследовать:

- зависимость качества востановления от размера скрытого представления;
- зависимость качества востановления от размера исходного пространства;
- зависимость качества востановления от отношения размера скрытого представления к исходном;
- зависимость качества востановления от сложности модели нейросети.

Все выводы должны быть представленны в формате tensorboard (каждый набор параметров, свой график, пример --- второй семинар).


P.S. в рамках семинара мы востанавливали параметры бернуливского распределения, так как изображение это числа от 0 до 1 --- вероятности бернуливской случайной величины. Теперь требуется, чтобы модель decoder востанаввливала параметры нормального случайного вектора.

P.S.S. в качестве модели encoder и decoder можно выбирать любую архитектуру нейросети.

Задача 5. Генерация аннотации к изображению
-------------------------------------------
Требуется построить модель генерации описания изображения по изображению. В качестве выборки рассматривается подвыборка вывборки `COCO <https://cocodataset.org/#download>`_. Требуется в качестве модели encoder использовать предобученую модель resnet152 без последнего слоя (по аналогии с `16-м семинаром <https://github.com/andriygav/MachineLearningSeminars/blob/master/sem16/main.ipynb>`_), в качестве модели decoder обучить LSTM модель.

Все выводы должны быть представленны в формате tensorboard (показать, как менялись описания одного и того же изображения при обучении модели, а также график качества в зависимости от итерации).


P.S. Может быть полезным `код <https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning>`_. 

P.S.S Рекомендуется взять подвыборку общей выборки из сайта COCO.
