Отбирать можно многими способами. Например, по удельной важности объекта: оцениваем, как сильно добавление объекта в выборку меняет
ошибку и делим на количество элементов, с которыми изменение этой ошибки мерили (там брали только близкие через ядра)

В случае байесовского подхода к экспоненциальному семейству распределений всё достаточно просто - там все величины зависят от статистик по выборке,
которые легко пересчитываются в онлайн-режиме.

Есть вариация онлайн градиентного спуска (только по последнему объекту).
В случае с мнк + л2 регуляризтором есть аналитическая формула для решения, для которой есть рекуррентное соотношение в случае добавления одного объекта.

В случае бустинга алгоритм hedge:  мы не меняем количество решений, а перевзвешиваем их в ансамбле, а потом дообучаем. 
В случае нейросетей (hedge+backprop) строится связующий слой для промежуточных архитектур, а результат - их агрегация. 
Идея в том, что связующий слой будет по началу учитывать только маленькие архитектуры, а в дальнейшем смотреть на более сложные.

Если же в онлайн режиме будут приходить новые классы - общая идея в том, чтобы регуляризатор ставить не только для обучения на новые объекты,
но и с дистилляцией: мы не должны забыть свои результаты на предыдущих моделях (в основном делают отбор эталонных и сравнивают с ними через энтропию).
