Повторили материал про нейронные сети: батч-нормализацию, дропаут (он решил сказал что он на минибатчах именно делается).

Базовые нейронные сети:
Сверточная - просто умножается окрестность покоординатно на некоторую матрицу с весами и берется сумма элементов
(размер изображения практически не меняется), пулинг - мы делим изображение на  фиксированные блоки,
в каждом из них применяем агрегирующую функцию (например, максимум), размер изображения при этом уменьшается в несколько раз.

Прием аугментейшен - мы пополняем коллекцию экземплярами с искажениями.
Прием пропуска нескольких слоев (shortcut) в ResNet, либо его взвешенная версия highway network.

Общая идея - сначала векторизация объекта (через определение окрестности мы делаем свертки + пуллинг) ,а затем можно запустить полносвязную нейронную сеть.

В задаче прогнозирования последовательностей основная идея - существование некоторого скрытого состояния. Оптимизация происходит по параметрам U,V,W.
У нее минус - паралич.

Ещё одна популярная сверточная нейронная сеть - LSTM, в ней идея ввести вектор состояния в момент времени и  
преобразовывать его, передавая в +- сжатом виде. Куча их вариаций. 
