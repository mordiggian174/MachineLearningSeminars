Основных подхода два: либо отбирать эталонные объекты, либо синтезировать специальные для асессора.

В общем случае максимизируется некоторый критерий важности получения метки объекта. Например, степень неуверенности классификатора на нем, либо энтропия,
либо разница между  максимальными вероятностями.

Если нам дан целый ансамбль алгоритмов, то можно отбирать те объекты, на которых большие разногласия. Либо на которых суммарная КЛ дивергенция
средний ответа с ответом модели сильно большая,
либо на которых простое голосование имеет большую энтропию.

Можно искать объект, антиградиент которого максимален. Но тк мы метки не знаем, мы сделаем матожидание. 

В случае синтеза нового объекта для асессора - можно пользоваться неградиентным методом Нилдера-Мида (отражения и стягивания симплексов).

Есть методы с минимизацией дисперсии после дообучения модели с размеченным объектом. 
Есть эпсилон-жадные стратегии, их вариации с сеткой для параметра эпсилон, которая меняется в ходе алгоритма (EG алгоритм).

Если асессоров много, то можно вводить для них параметры компетентности. Делать либо простое голосование, либо в зависимости от их компетенции
(формула для наивного байеса, например).

Есть модели, моделирующие трудности объектов, компетенции асессоров по темам. Также можно брать асессора не только по его компетенции,
но и по уровню занятости, опыту, и другой информации (взвешивается с ней).
