

В модели классификации вместо разрывной функции индикатора ошибки берут какую-нибудь её мажоранту.
В зависимости от мажоранты ( либо аппроксимации) выделяют различные алгоритмы.

Модель МакКаллока-Питтса - обычная модель с функцией активации и сдвигом.
Минимизация эмпирического риска происходит путем градиентного спуска.

Стохастический градиентный спуск - просто учитываем лосс не от всей выборки, а только от случайно выбранного объекта. Так же там есть параметр
скорости обучения и скорости забывания.

В чем проблема простой реализации? Подсчет лосса после микрошага намного дольше, чем сам шаг. 
Для этого придумали брать среднее арифметическое за какое-то количество шагов. А потом развили эту идею до экспоненциального скользящего среднего.

На листочке -1- описал варианты усреднения. Дальнейшая проблема - начальная инициализация. Там много подходов:
Случайно, нулевое, аналитическое из МНК, либо мультистарт + случайность.

Как можно модифицировать стохастический градиентный спуск? Брать попеременно объекты из разных классов, так как скорее всего они далеко друг от
друга находятся чем объекты одного класса (типа быстрее будет изменяться градиент?), можно ранжировать вероятности пропорционально margin - чем больше он,
тем меньше интересен объект, он уже хорошо расположен. Можно ввести пороги по margin, начиная с которых объекты вообще не рассматривать.

Параметр h можно выбирать как ряд, который рассходится в 1 степени но сходится во второй. Но на практике обычно либо решают задачу оптимизации по лернинг
рейту на каждом шаге, либо Метод касательных (Ньютона-Рафсона) в предположении диагональности гессиана. Он сохраняет в себе скорость первого порядка 
вне локального минимума, а в локальном минимуме пытается видеть поверхность квадратичной, что дает свои плюсы. 

Регуляризация для борьбы с переобучением не сильно портит метод, он легко корректируется.

Плюсы стохастического градиентного метода: онлайн-метод, легко реализуется, обобщается на гладкие функции, подходит для больших данных.

Минусы: подбирать эвристики - это искусство


Можно посмотреть на задачу с точки зрения вероятности и воспользоваться методом максимального правдоподобия, тогда при соответствующем выборе функции потерь постановки окажутся эквивалентны минимизации ошибок. 

Более того, если предположить, что веса модели тоже как-то случайно зависят от вектора гиперпарамеров, то коэффициенты регуляризации можно будет объяснить
(пример л2 нормы и нормального распределения, л1 нормы и распределения лапласа) 

При задаче классификации если взять в качестве аппроксимации пороговой функции потерь логарифмическую 
То в соотвествии с правилом выше модель условной вероятности примет вид, и метод максимизации правдоподобия примет вид минимизации ошибок 	

Аналогично можно через софтмакс записать многоклассовую задачу (уже без логарифмов, сразу в вероятностях задача на максимизацию)
Ну и главный бонус логистической регрессии - мы научились не только предсказывать класс, но и говорить вероятности принадлежности классам. А тогда мы можем моделировать будущее в соответствии с этими вероятностями и находить различные квантили и так далее.
