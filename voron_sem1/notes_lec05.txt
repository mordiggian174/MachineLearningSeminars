RSS - residual sum of squares - оптимальноез начение МНК

Занимательно, что если предполагать гауссовский несмещённый шум, то МНК и ММП совпадут, а веса в МНК - обратно пропорциональны дисперсии.

*Пропускаю все что связано с проекционной матрицей
Вроде бы вся идея - что МНК - это орто-проецирование вектора у на линейное пространство признаковых описаний*

Про устойчивость и мультиколлинеарность: возникает огромное число обусловленности, которое погрешность в измерениях увеличивает во столько же раз 
в погрешности ответа. Метод борьбы: регуляризация, отбор признаков, преобразование признаков.

Преобразование признаков можно делать линейным, тогда недолго идти до применения сингулярного разложения и малорангового  приближения матрицы. Его 
называют также декоррелирующим преобразованием или преобразованием Карунена-Лоэва.

В конечном итоге это ещё один способ бороться с собственными числами в знаменателе равными 0. Все такие методы называются спектральным методом 
наименьших квадратов (например, л2 регуляризация - тоже она). 


После l2 регуляризация выписывается аналитическое решение и становится видно, что теперь устойчивость есть (хотя точность могли и потерять). 
Важно отметить, что коэффициент регуляризация оптимизировать не так сложно, если пользоваться сингулярным разложением.

Ещё одно обоснование  L1 регуляризации через геометрию поверхностей уровня
