Говорим про метрики. 
Самая простая (accuracy) не учитывает разную важность ошибок и дисбаланс классов.

Идея следующая: строить дискриминантную функцию отдельно, а затем уже подбором свободного коэффициента искать решения для различных стоимостей ошибок (аналог thrashhold).  
Возникает ROC-AUC метрика. И вопрос? А почему мы минимизировали один функционал, а мерить будем другим.
Попробуем оптимизировать сразу AUC. Её можно будет переписать определенным образом как сумму по парам разных классов. Вводим аппроксимацию AUC и делаем стохастический градиентный спуск (только надо уже случайно выбирать пару из разных классов).

Минусы ROC-AUC: они инвариантны относительно монотонных изменений дискриминантной функции, а ведь это наши вероятности (и они важны).

Вводятся метрики recall, precision, sensitivity, specificity. На многоклассовой классификации также вводятся их аналоги, но уже двумя способами: на макро и микроуровне.

Плюсы ROC кривой: она не зависит от баланса классов, так как там в обоих осях доли каждого из них. Если больше интересуют вероятности, то надо использовать лог-лосс. А для задач поиска лучше recall, precision (там объем нерелевантных объектов не используется)

Затем блок про критерии оценивания. Понятие внешнего и внутреннего критериев. Понятие CCV, LOO, q-fold CV, tq-fold CV.
Определяются критерии непротиворечивости модели (разбиваем выборку на две одинаковые части, обучаем модели, а потом смотрим на разницу в предсказаниях), либо его повторение t раз, что по факту будет равно t-2 CV.

Переходим к задаче отбора признаков. Для этого нам нужен некоторый внешний критерий. Тогда спрятав сложность его вычисления, можно считать
что отбор признаков - это задача дискретной оптимизации с параметром - указанием номеров признаков.
Примеры - полный поиск (обрезанный), жадное добавление, жадное удаление, можно это делать поочередно, МГУА ( мы на каждом шаге храним не один оптимум,
а целое ядро  заданной мощности лучших решений). И очень похожий на него эволюционный алгоритм. Куча эвристик типа элитаризма, островной модели эволюции,
повышения мутации для адаптации, определять информативность признаков. Случайный поиск с адаптацией (мы хотим породить такой вектор вероятностей признаков, что
случайный набор, сгенерированный в соответствии с ними, будет +- хорош).

В целом, они все - реализация естественного отбора.
