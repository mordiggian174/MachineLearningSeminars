<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Machine Learning Seminars</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Machine Learning Seminars</h1>
</header>
<h1 id="объявление">Объявление</h1>
<ul>
<li>Семинары в весеннем семестре пока будут в дистанционном режиме по ссылке, которая указана ниже.</li>
</ul>
<h1 id="полезные-ссылки">Полезные ссылки</h1>
<ul>
<li>Плейлист лекций и семинаров: <a href="https://www.youtube.com/playlist?list=PLk4h7dmY2eYHHTyfLyrl7HmP-H3mMAW08">2020-2021</a>; <a href="https://youtube.com/playlist?list=PLk4h7dmY2eYFmowaPqjFDzSokiiLq5TkT">2021-2022</a></li>
<li><a href="http://www.machinelearning.ru/wiki/index.php?title=Машинное_обучение_%28курс_лекций%2C_К.В.Воронцов%29">Курс лекций К.В. Воронцова.</a></li>
<li><a href="https://github.com/MelLain/mipt-python">Курс Мурата Апишева по python.</a></li>
<li><a href="https://us06web.zoom.us/j/81766985440?pwd=UWdrbk5OYVhFdm1Jczlsc0lpZTBkQT09">Ссылка в zoom для лекции и семинара.</a></li>
<li><a href="grabovoy.av@phystech.edu">Почта для связи.</a></li>
</ul>
<h1 id="осений-семестр">Осений семестр</h1>
<h2 id="курсовое-домашнее-задание">Курсовое домашнее задание:</h2>
<h3 id="первое-задание">Первое задание:</h3>
<ul>
<li>Начало: 15:30 25.09.2021</li>
<li>Дедлайн: 23:59 17.10.2021.</li>
<li><a href="https://forms.gle/mydS288qEzGtNP568">Ссылка для сдачи задания</a>.</li>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/hometask/task1-1/generator.ipynb">Генератор задания</a>:</dt>
<dd><ul>
<li>В качестве почты нужно ввести почту в домене @phystech.edu.</li>
<li>После ввода почты, вам будет предложена выборка с ссылкой для скачивания, а также методы, которые нужно проанализировать для данной выборки.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Требуется:</dt>
<dd><ul>
<li><dl>
<dt>Провести анализ выборки:</dt>
<dd><ul>
<li>Определить тип признаков.</li>
<li>Выполнить визуальный анализ данных.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Выполнить препроцесинг данных:</dt>
<dd><ul>
<li>Преобразовать категориальные признаки в вещественные.</li>
<li>Отнормировать признаки.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Провести эксперимент для предложеных методов:</dt>
<dd><ul>
<li>Выполнить подбор гиперпараметров.</li>
<li>Подобрать регуляризаторы.</li>
<li>Получить итоговые модели.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Описать полученые результаты:</dt>
<dd><ul>
<li>Какая модель лучше и почему.</li>
<li>С какими проблемами столкнулись во время выполнения, возможно недочеты стандартных библиотек.</li>
<li>Совпадают ли полученные результаты с ожидаемыми результатами.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Оценивание:</dt>
<dd><ul>
<li><dl>
<dt>Качество кода (1б):</dt>
<dd><ul>
<li>Код должен работать у проверяющего.</li>
<li>Код должен был понятен без автора.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Качество анализа (3б):</dt>
<dd><ul>
<li>Анализ выборки.</li>
<li>Анализ гиперпараметров.</li>
<li>Анализ результатов для разных моделей.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Качество отчета (1б):</dt>
<dd><ul>
<li>Учитывается полнота отчета.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="второе-задание">Второе задание:</h3>
<ul>
<li>Начало: 15:30 20.11.2021.</li>
<li>Дедлайн: 23:59 12.12.2021.</li>
<li><a href="https://www.kaggle.com/c/fall-ml2-mipt-2021/overview">Ссылка на задание</a>.</li>
<li><a href="https://forms.gle/KBR2npxT17gnnspd8">Ссылка для сдачи оформленного решения</a>.</li>
<li><dl>
<dt>Требуется:</dt>
<dd><ul>
<li>Отправить свое решение в csv формате на kaggle.com.</li>
<li>Отправить ноутбук с решением через гугл форму.</li>
</ul>
</dd>
</dl></li>
</ul>
<h2 id="план-занятий">План занятий</h2>
<h3 id="вводный-семинар">Вводный семинар</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem1/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Теореотическая часть:</dt>
<dd><ul>
<li>Общие идеи оптимизации, функции ошибки и тд.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>При помощи sklearn показать пример Ирисов Фишера.</li>
<li>Понятие модели алгоритмов, алгоритм обучения, процесс оптимизации для конкретной задачи.</li>
<li>Переход от бинарной к многоклассовой.</li>
<li>Переобучение. Борьба с переобучениям (начало).</li>
<li>Немного о типах задач машинного обучения: прикладные и исследовательские</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>В задаче по переходу от бинарной классификации к многоклассовой добавить константу и скорректировать соответстветсвующие разделяющие гиперплоскости.</li>
<li>Подсказка: в LogisticRegresion нужно добавить специальный параметр fit_intercept=False, чтобы внутри черного ящика своя константта не добавлялась(влият на результат).</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="линейные-методы-классификации-и-регрессии-метод-стохастического-градиента">Линейные методы классификации и регрессии: метод стохастического градиента</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem2/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Теореотическая часть:</dt>
<dd><ul>
<li>Анализ стохастического градиента на сходимость.</li>
<li>Задача линейной регрессии, МНК в общем случае.</li>
<li>Постановка задачи линейной регрессии через правдоподобие, вероятностные предположения о данных + регуляризаций.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Разбор домашнего задания.</li>
<li>Метод стохастического градиента на практике.</li>
<li>Использования torch framework для нахождения градиента сложной функции.</li>
<li>Вероятностная постановка задачи машинного обучения. Регуляризация l1, l2.</li>
<li>Анализ решения задачи оптимизации от параметра регуляризации.</li>
<li>Выбор параметра регуляризации при помощи LOO.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Используя вероятностную постановку задачи для линейной регрессии с априорным предположением p(w) = N(0, I) получить аналитическое решение на оптимальный вектор параметров w.</li>
<li>Использовать метод Cross-Validation вместо метода LOO для выбора оптимального параметра регуляризации gamma.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="нейронные-сети-autograd">Нейронные сети: Autograd</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem3/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Теореотическая часть:</dt>
<dd><ul>
<li>Автоматическое диференцирование.</li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Разбор домашнего задания.</li>
<li>Построение простой нейросетевой модели: многослойный персептрон.</li>
<li>Обучение персептрона на выборке MNIST.</li>
<li>Подбор гиперпараметров модели.</li>
<li>Пррореживание сетей (без кода, только графики).</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Проделать то, что было на семинаре для выборки FashionMnist: подбор гиперпараметров модели (выполнить более подробно чем на семинаре), также провести анализ полученных результатов.</li>
<li>Указать какие минусы вы увидели в подборе гиперпараметров на семинаре (их как минимум 3).</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="метрические-методы-классификации-и-регрессии">Метрические методы классификации и регрессии</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem4/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Разбор домашнего задания.</li>
<li>Пример как можно отказаться от признаков в линейном классификаторе.</li>
<li>Метод ближайших соседей, анализ разного количества соседей.</li>
<li>Ядра в методе ближайших соседей.</li>
<li>Метод Парзеновского окна.</li>
<li>Метод потенциальных функций (реализация).</li>
<li>Отбор эталонных элементов, алгоритм STOLP.</li>
<li>Формула Надарая Ватсона.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Выбрать один из метрических классификаторов (классификации или регрессии) и выполнить поиск оптимальных гиперпараметра при помощи кросс валидации.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="линейные-методы-классификации-и-регрессии-метод-опорных-векторов">Линейные методы классификации и регрессии: метод опорных векторов</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem5/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>SVM для классификации.</li>
<li>Примеры использования ядер для SVM.</li>
<li>SVM для регрессии.</li>
<li>Генерация признаков на основе опорных элементов.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Провести эксперимент с полиномиальным ядром: сгенерировать синтетическую выборку, на которой полиномиальное ядро имеет лучшее качество аппроксимации чем rbf и линейное ядро.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="многомерная-линейная-регрессия.-метод-главных-компонент">Многомерная линейная регрессия. Метод главных компонент</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem6/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Многомерная линейная регрессия.</li>
<li>Сингулярное разложение.</li>
<li>Регуляризация для многомерной регрессии: используя SVD.</li>
<li>Зависимость качества аппроксимации от числа обусловлености.</li>
<li>Метод главных компонент: визуализация MNIST.</li>
<li>Метод главных компонент: для изображений.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Доказать лемму из семинара.</li>
<li>Для синтетически сгенерированной выборки (beta=2, mu=0.01) построить график зависимости качества аппроксимации контрольной вбыорки от коэффициента регуляризации. Сравнить скорость работы в случае использования SVD разложения и без него.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="нелинейная-регрессия.-обощенные-линейные-модели.-нестандартные-функции-потерь.">Нелинейная регрессия. Обощенные линейные модели. Нестандартные функции потерь.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem7/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Нелинейная регрессия: пример задачи.</li>
<li>Сравнение градиентного спуска, метода Ньютона-Рафсона, метода Ньютона-Гауса.</li>
<li>Обобщенно линейные модели: оптимальный размер выборки.</li>
<li>Функция потерь для задачи поиска близких предложений.</li>
<li>Визуализация сходимости метода Ньютона Рафсона и стохастического градиента.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt><a href="https://forms.gle/9oYB7KVaJUndL7L26">Домашнее задание</a>:</dt>
<dd><ul>
<li>Использовать модель для векторизации предложений из семинара. На основе полученных векторов решить задачу сентимент анализа для выборки Twitter (задача бинарной классификации). В качестве модели рассмотреть логистическую регрессию. Рекомендуется использовать модель Perceptron с третьего семинара, а также функцию ошибки torch.nn.BCELoss. Ссылка на данные: <a href="https://drive.google.com/file/d/1k4JrnVcoePEENCYt5iy17dyV_h133j2X/view?usp=sharing">https://drive.google.com/file/d/1k4JrnVcoePEENCYt5iy17dyV_h133j2X/view?usp=sharing</a> (предложения для классификации это последний столбец, а целевая переменная это второй столбец).</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="критерии-выбора-моделей-и-методы-отбора-признаков.">Критерии выбора моделей и методы отбора признаков.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem8/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Оценка качества моделе: внешний и внутрений критерии.</li>
<li>Отбор признаков: полный перебор, алгоритм Add, алгоритм Add-Del.</li>
<li>Качество классификации: Precision, Recall.</li>
<li>Пример задачи information retrieval.</li>
<li>О составлении выборки для постановки задачи ML.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>реализовать метода отбора признаков Add-Del.</li>
<li>предложения внешний критерий качества для задачи поиска ошибок в текстах.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="логические-методы-классификации.">Логические методы классификации.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem9/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Логический классификатор реализация.</li>
<li>Примеры задач для решения логичеким классификатором.</li>
<li>Критерии информативности.</li>
<li>Решающий список, простая реализация.</li>
<li>Решающее дерево.</li>
<li>Случайный лес.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>в реализованый метод построение логистического классификатора добавить возможность оптимизации по критерию Джини.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="поиск-ассоциативных-правил.">Поиск ассоциативных правил.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem10/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Постановка задачи ассоциативных правил.</li>
<li>Синтетичекий пример.</li>
<li>Пример реальных данных из kaggle.</li>
<li>Алгоритм APriory.</li>
<li>Алгоритм FP-growth.</li>
<li>Обобщение для вещественных данных.</li>
<li>Обобщенные ассоциативные правила.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>выполнить анализ ассоциативных правил, которые получены алгоримом FP-growth. Расмоттреть только те правила, которые содержат более 3 элементов</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="композиции-классификаторов.">Композиции классификаторов.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem11/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>DummyEnsemble.</li>
<li>AdaBoost.</li>
<li>Градиентный бустинг, XGBoost.</li>
<li>Пример реальных данных из kaggle.</li>
<li>RandomForest.</li>
<li>Mixture Of Expert.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Рассматривается две выборки: <a href="https://archive.ics.uci.edu/ml/datasets/Shill+Bidding+Dataset">выборка</a> и <a href="https://archive.ics.uci.edu/ml/datasets/Speaker+Accent+Recognition">выборка</a>. Для обоих выборок построить AdaBoost, GradientBoosting, RandomForest, Bagging. Сравнить качество на обоих выборках. Отличается ли результат? Почему?</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="композиции-классификаторов-градиентный-бустинг.">Композиции классификаторов (градиентный бустинг).</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem12/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>ComBoost.</li>
<li>Gradient Boosting.</li>
<li>XGBoost.</li>
<li>CatBoost.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Реализовать комитетный бустинг для задачи регрессии.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="байесовская-теория-классификации.">Байесовская теория классификации.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem13/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Принцип максимума правдоподобия: визуализация.</li>
<li>Востановление плотности по империческим данным.</li>
<li>LOO для ввыбора ширины окна.</li>
<li>Наивный байесовский классификатор.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Получить оценку параметров нормального распределения из принципа максимума правдоподобия.</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="методы-кластеризации-и-обучение-на-неразмеченных-данных.">Методы кластеризации и обучение на неразмеченных данных.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem14/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Задача кластеризации.</li>
<li>Примеры кластеров.</li>
<li>K-means.</li>
<li>DBSCAN.</li>
<li>Иерархическая кластеризация.</li>
<li>Частичное обучение.</li>
<li>Self-training, 1970.</li>
<li>Неразмеченные данные в глубоком обучении.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
<li><dl>
<dt>Домашнее задание:</dt>
<dd><ul>
<li>Самому сравнить разные методы кластеризации для трех концентрических окружностей.</li>
</ul>
</dd>
</dl></li>
</ul>
<h1 id="весений-семестр">Весений семестр</h1>
<h2 id="курсовое-домашнее-задание-1">Курсовое домашнее задание:</h2>
<h3 id="первое-задание-1">Первое задание:</h3>
<ul>
<li>Дедлайн: 23:59 14.03.2021. Жесткий дедлайн 21.03.2021, каждый день оценка по каждой задаче уменьшается на 0.05. Суммарное количество баллов за каждую задачу 1.</li>
<li>Задание доступно по <a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/hometask/task2-1/">ссылке</a>.</li>
<li>Ссылка для сдачи задания <a href="None">тут</a>.</li>
</ul>
<h3 id="второе-задание-1">Второе задание:</h3>
<ul>
<li>Дедлайн: Дедлайн 23:59 01.04.2021(task 2-2.1); 11.04.2021(task 2-2.2) 23:59 02.05.2021 (task 2-2.3)</li>
<li>Задание доступно по <a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/hometask/task2-2/">ссылке</a>.</li>
<li>Ссылка для сдачи задания <a href="None">тут</a>.</li>
</ul>
<h2 id="план-занятий-1">План занятий</h2>
<h3 id="глубокие-нейронные-сети.-сверточные-нейросети-и-рекурентные-сети.">Глубокие Нейронные Сети. Сверточные нейросети и Рекурентные сети.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem15/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Сверточные нейронные сети.</li>
<li>Отслеживание обучения при помощи tensorboard.</li>
<li>Рекурентные нейронные сети.</li>
<li>Использование предобученных моделей.</li>
<li>Интерпретируемость ответов нейросети.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<p>Нейронные сети. Автокодировщик. Transfer Learning. Генеративно-Состязательные сети. ******************************************************************************* - <a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem16/main.ipynb">Семинар</a>: - Практическая часть: - Автокодировщик. - Линейный автокодировщик. - Автокодировщик на основе CNN. - Вариационный автокодировщик. - Перенос обучения с предварительно обученой модели. - Генеративно состязательные сети.</p>
<h3 id="векторное-представления-текстов.">Векторное представления текстов.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem17/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Пример классификации твитов.</li>
<li>Зачем нужна векторизация?.</li>
<li>Токенизация текстов.</li>
<li>Word2Vec (на основе модели FastText).</li>
<li>FastText модель (сжатая до emb-dim=10 для легковестности).</li>
<li>Задачи для unsupervise training моделей векторизации.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="attention-is-all-you-need.-трансформеры.">Attention is all you need. Трансформеры.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem18/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Модель внимания в рекурентных нейронных сетях.</li>
<li>Трансформеры.</li>
<li>T2T переводчик.</li>
<li>BPE токенизация.</li>
<li>BERT.</li>
<li>LaBSE.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="тематическое-моделирование.">Тематическое моделирование.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem19/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Модель LDA.</li>
<li>Модель PLSA (bigartm).</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="пояснение-к-домашнему-заданию.">Пояснение к домашнему заданию.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem20/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Задачи из ДЗ.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="задача-ранжирования.">Задача ранжирования.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem21/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Базовые понятие.</li>
<li>Пример задачи ранжирования.</li>
<li>Пример рекомендательной системы.</li>
<li>Обучение поисковика на базе pyserini.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="рекомендательные-системы.">Рекомендательные системы.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem22/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Константная модель.</li>
<li>Кореляционная система.</li>
<li>SLIM.</li>
<li>SVD.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="временные-ряды.">Временные ряды.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem23/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Авторегрессионая модель.</li>
<li>Экспоненциальное сглаживание.</li>
<li>Кластерный анализ временных рядов.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="онлайновое-обучение.">Онлайновое обучение.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem24/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li>Практическая часть:</li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="обучение-с-подкреплением.">Обучение с подкреплением.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem25/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Стационарный многорукий бандин.</li>
<li>Нестационарный многорукий бандин.</li>
<li>Задача о заплыве.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="активное-обучение.">Активное обучение.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem26/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Практическая часть:</dt>
<dd><ul>
<li>Активное обучение со случайным добавлчющим элементом.</li>
<li>Активное обучение с добавлением элемента с максимальной дисперсией.</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
<h3 id="заключительное-занятие.">Заключительное занятие.</h3>
<ul>
<li><dl>
<dt><a href="https://github.com/andriygav/MachineLearningSeminars/blob/master/sem27/main.ipynb">Семинар</a>:</dt>
<dd><ul>
<li><dl>
<dt>Теоретическая часть:</dt>
<dd><ul>
<li>Разбор Posterior Sampling</li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl></li>
</ul>
</body>
</html>
